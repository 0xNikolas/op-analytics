{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ch uploads\n"
     ]
    }
   ],
   "source": [
    "print('start ch uploads')\n",
    "#Clickhouse db w/ Goldsky\n",
    "# https://clickhouse.com/docs/en/integrations/python\n",
    "\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "import clickhouse_connect as cc\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../helper_functions\")\n",
    "import duneapi_utils as d\n",
    "import pandas_utils as p\n",
    "import clickhouse_utils as ch\n",
    "import csv_utils as cu\n",
    "import google_bq_utils as bqu\n",
    "sys.path.pop()\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "client = ch.connect_to_clickhouse_db() #Default is OPLabs DB\n",
    "# client.close()\n",
    "\n",
    "table_name = 'daily_aggegate_l2_chain_usage_goldsky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_mappings_list = [\n",
    "    # {'schema_name': 'zora', 'display_name': 'Zora', 'has_blob_fields': False},\n",
    "    # {'schema_name': 'pgn', 'display_name': 'Public Goods Network', 'has_blob_fields': False},\n",
    "    # {'schema_name': 'base', 'display_name': 'Base', 'has_blob_fields': False},\n",
    "    # {'schema_name': 'op', 'display_name': 'OP Mainnet', 'has_blob_fields': True},\n",
    "    {'schema_name': 'mode', 'display_name': 'Mode', 'has_blob_fields': False},\n",
    "    {'schema_name': 'metal', 'display_name': 'Metal', 'has_blob_fields': False},\n",
    "    {'schema_name': 'fraxtal', 'display_name': 'Fraxtal', 'has_blob_fields': True},\n",
    "    {'schema_name': 'bob', 'display_name': 'BOB (Build on Bitcoin)', 'has_blob_fields': False},\n",
    "    {'schema_name': 'cyber', 'display_name': 'Cyber', 'has_blob_fields': True},\n",
    "    # Add more mappings as needed\n",
    "]\n",
    "chain_mappings_dict = {item['schema_name']: item['display_name'] for item in chain_mappings_list}\n",
    "\n",
    "block_time_sec = 2\n",
    "\n",
    "trailing_days = 9999\n",
    "max_execution_secs = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_directory = \"inputs/sql/\"\n",
    "\n",
    "query_names = [\n",
    "        # Must match the file name in inputs/sql\n",
    "        \"ch_template_alltime_chain_activity\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_template_alltime_chain_activity - mode\n",
      "ch_template_alltime_chain_activity - mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_71242/4161144624.py:23: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~has_blob_fields:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_template_alltime_chain_activity - metal\n",
      "ch_template_alltime_chain_activity - metal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_71242/4161144624.py:23: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~has_blob_fields:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch_template_alltime_chain_activity_updated - fraxtal\n",
      "ch_template_alltime_chain_activity_updated - fraxtal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_71242/4161144624.py:23: DeprecationWarning: Bitwise inversion '~' on bool is deprecated. This returns the bitwise inversion of the underlying int object and is usually not what you expect from negating a bool. Use the 'not' operator for boolean negation or ~int(x) if you really want the bitwise inversion of the underlying int.\n",
      "  if ~has_blob_fields:\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": ":HTTPDriver for https://pdmv9lhojy.us-west-2.aws.clickhouse.cloud:8443 returned response code 404)\n Code: 47. DB::Exception: There's no column 'b.block_timestamp' in table 'b': While processing b.block_timestamp: While processing SELECT DATE_TRUNC('day', toDateTime(t.block_timestamp)) AS dt, chain, network, CAST(2, 'Float64') AS block_time_sec, COUNT(*) AS num_raw_txs, COUNTDistinct(t.block_number) AS num_blocks, SUM(multiIf((gas_price = 0) AND (to_address = '0x4200000000000000000000000000000000000015'), 1, 0)) AS l2_num_attr_deposit_txs_per_day, SUM(multiIf((gas_price = 0) AND (to_address = '0x4200000000000000000000000000000000000007'), 1, 0)) AS l2_num_user_deposit_txs_per_day, SUM(multiIf(gas_price > 0, 1, 0)) AS l2_num_txs_per_day, SUM(multiIf((receipt_status = 1) AND (gas_price > 0), 1, 0)) AS l2_num_success_txs_per_day, COUNTDistinct(from_address) AS num_senders_per_day, SUM(t.receipt_gas_used) AS l2_gas_used, SUM(CAST(receipt_l1_gas_used, 'Nullable(Int64)')) AS l1_gas_used_on_l2, SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)') * COALESCE(toInt64(NULL), receipt_l1_fee_scalar)) AS l1_gas_paid, SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)')) AS blob_gas_paid, SUM(length(unhex(input)) - 1) AS calldata_bytes_l2_per_day, SUM(multiIf(gas_price > 0, CAST(receipt_l1_gas_used, 'Nullable(Float64)') * receipt_l1_fee_scalar, 0)) AS l1_gas_paid_user_txs, SUM(multiIf(gas_price > 0, CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)'), 0)) AS blob_gas_paid_user_txs, SUM(multiIf(gas_price > 0, receipt_l1_gas_used, 0)) AS l1_gas_used_user_txs_l2_per_day, SUM(multiIf(gas_price > 0, length(unhex(input)) - 1, 0)) AS calldata_bytes_user_txs_l2_per_day, SUM(multiIf(gas_price > 0, t.receipt_gas_used, 0)) AS l2_gas_used_user_txs_per_day, SUM(CAST((gas_price * t.receipt_gas_used) + receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000.) AS l2_eth_fees_per_day, median(multiIf(gas_price > 0, CAST((gas_price * t.receipt_gas_used) + receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000., NULL)) AS median_l2_eth_fees_per_tx, SUM(CAST(receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000.) AS l1_contrib_l2_eth_fees_per_day, SUM(CAST(gas_price * t.receipt_gas_used, 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_per_day, SUM(((CAST(receipt_l1_gas_used, 'Nullable(Float64)') * COALESCE(toInt64(NULL), receipt_l1_fee_scalar)) * CAST(receipt_l1_gas_price, 'Nullable(Float64)')) / 1000000000000000000.) AS l1_l1gas_contrib_l2_eth_fees_per_day, SUM(((CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)')) * CAST(CAST(NULL, 'Nullable(Float64)'), 'Nullable(Float64)')) / 1000000000000000000.) AS l1_blobgas_contrib_l2_eth_fees_per_day, SUM(CAST(base_fee_per_gas * t.receipt_gas_used, 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_base_fee_per_day, SUM(CAST(gas_price - (base_fee_per_gas * t.receipt_gas_used), 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_priority_fee_per_day, SUM((16 * (length(replace(toString(unhex(input)), '\\0', '')) - 1)) + (4 * ((length(unhex(input)) - 1) - (length(replace(toString(unhex(input)), '\\0', '')) - 1)))) AS input_calldata_gas_l2_per_day, SUM(multiIf(gas_price > 0, (16 * (length(replace(toString(unhex(input)), '\\0', '')) - 1)) + (4 * ((length(unhex(input)) - 1) - (length(replace(toString(unhex(input)), '\\0', '')) - 1))), 0)) AS input_calldata_gas_user_txs_l2_per_day, SUM(receipt_l1_gas_used / 16) AS compressedtxsize_approx_l2_per_day, SUM(multiIf(gas_price > 0, receipt_l1_gas_used / 16, 0)) AS compressedtxsize_approx_user_txs_l2_per_day, SUM((CAST(receipt_l1_gas_price, 'Nullable(Float64)') / CAST(1000000000., 'Nullable(Float64)')) * CAST(receipt_l1_gas_used, 'Nullable(Float64)')) / SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)')) AS avg_l1_gas_price_on_l2, SUM(multiIf(gas_price > 0, CAST(t.receipt_gas_used * gas_price, 'Nullable(Float64)') / 1000000000., NULL)) / SUM(multiIf(gas_price > 0, t.receipt_gas_used, NULL)) AS avg_l2_gas_price, SUM(multiIf(gas_price > 0, (CAST(t.receipt_gas_used, 'Nullable(Float64)') * CAST(base_fee_per_gas, 'Nullable(Float64)')) / 1000000000., NULL)) / SUM(multiIf(gas_price > 0, t.receipt_gas_used, NULL)) AS base_fee_gwei, SUM(multiIf(gas_price = 0, 0, CAST(t.receipt_gas_used * receipt_l1_gas_price, 'Nullable(Float64)')) / 1000000000000000000.) AS equivalent_l1_tx_fee, AVG(multiIf(gas_price > 0, receipt_l1_fee_scalar, NULL)) AS avg_l1_fee_scalar, coalesce(AVG(multiIf(gas_price > 0, CAST(NULL, 'Nullable(Float64)'), NULL)), 0) AS avg_l1_blob_fee_scalar FROM fraxtal_transactions AS t INNER JOIN fraxtal_blocks AS b ON (t.block_number = b.block_number) AND (t.block_timestamp = b.block_timestamp) WHERE (block_timestamp >= DATE_TRUNC('day', now() - toIntervalDay(9999))) AND (b.block_timestamp >= DATE_TRUNC('day', now() - toIntervalDay(9999))) GROUP BY 1, 2, 3, 4. (UNKNOWN_IDENTIFIER) (version 24.2.2.16288 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m                 query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceipt_l1_base_fee_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoInt64(NULL)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# Execute the query\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         result_df \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#         # Write to csv\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#         df.to_csv('outputs/chain_data/' + qn + '.csv', index=False)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#         # print(df.sample(5))\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#         time.sleep(1)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain_raw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gcp-env/lib/python3.12/site-packages/clickhouse_connect/driver/client.py:361\u001b[0m, in \u001b[0;36mClient.query_df\u001b[0;34m(self, query, parameters, settings, query_formats, column_formats, encoding, use_none, max_str_len, use_na_values, query_tz, column_tzs, context, external_data, use_extended_dtypes)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_df\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    342\u001b[0m              query: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    343\u001b[0m              parameters: Optional[Union[Sequence, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m              external_data: Optional[ExternalData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m              use_extended_dtypes: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m    Query method that results the results as a pandas dataframe.  For parameter values, see the\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    create_query_context method\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    :return: Pandas dataframe representing the result set\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gcp-env/lib/python3.12/site-packages/clickhouse_connect/driver/client.py:785\u001b[0m, in \u001b[0;36mClient._context_query\u001b[0;34m(self, lcls, **overrides)\u001b[0m\n\u001b[1;32m    783\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    784\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(overrides)\n\u001b[0;32m--> 785\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_query_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gcp-env/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:215\u001b[0m, in \u001b[0;36mHttpClient._query_with_context\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain; charset=utf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 215\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mserver_wait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m byte_source \u001b[38;5;241m=\u001b[39m RespBuffCls(ResponseSource(response))  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    223\u001b[0m context\u001b[38;5;241m.\u001b[39mset_response_tz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_tz_change(response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-ClickHouse-Timezone\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gcp-env/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:442\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[0;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[1;32m    440\u001b[0m     error_handler(response)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gcp-env/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py:366\u001b[0m, in \u001b[0;36mHttpClient._error_handler\u001b[0;34m(self, response, retried)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe ClickHouse server returned an error.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(err_str) \u001b[38;5;28;01mif\u001b[39;00m retried \u001b[38;5;28;01melse\u001b[39;00m DatabaseError(err_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: :HTTPDriver for https://pdmv9lhojy.us-west-2.aws.clickhouse.cloud:8443 returned response code 404)\n Code: 47. DB::Exception: There's no column 'b.block_timestamp' in table 'b': While processing b.block_timestamp: While processing SELECT DATE_TRUNC('day', toDateTime(t.block_timestamp)) AS dt, chain, network, CAST(2, 'Float64') AS block_time_sec, COUNT(*) AS num_raw_txs, COUNTDistinct(t.block_number) AS num_blocks, SUM(multiIf((gas_price = 0) AND (to_address = '0x4200000000000000000000000000000000000015'), 1, 0)) AS l2_num_attr_deposit_txs_per_day, SUM(multiIf((gas_price = 0) AND (to_address = '0x4200000000000000000000000000000000000007'), 1, 0)) AS l2_num_user_deposit_txs_per_day, SUM(multiIf(gas_price > 0, 1, 0)) AS l2_num_txs_per_day, SUM(multiIf((receipt_status = 1) AND (gas_price > 0), 1, 0)) AS l2_num_success_txs_per_day, COUNTDistinct(from_address) AS num_senders_per_day, SUM(t.receipt_gas_used) AS l2_gas_used, SUM(CAST(receipt_l1_gas_used, 'Nullable(Int64)')) AS l1_gas_used_on_l2, SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)') * COALESCE(toInt64(NULL), receipt_l1_fee_scalar)) AS l1_gas_paid, SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)')) AS blob_gas_paid, SUM(length(unhex(input)) - 1) AS calldata_bytes_l2_per_day, SUM(multiIf(gas_price > 0, CAST(receipt_l1_gas_used, 'Nullable(Float64)') * receipt_l1_fee_scalar, 0)) AS l1_gas_paid_user_txs, SUM(multiIf(gas_price > 0, CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)'), 0)) AS blob_gas_paid_user_txs, SUM(multiIf(gas_price > 0, receipt_l1_gas_used, 0)) AS l1_gas_used_user_txs_l2_per_day, SUM(multiIf(gas_price > 0, length(unhex(input)) - 1, 0)) AS calldata_bytes_user_txs_l2_per_day, SUM(multiIf(gas_price > 0, t.receipt_gas_used, 0)) AS l2_gas_used_user_txs_per_day, SUM(CAST((gas_price * t.receipt_gas_used) + receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000.) AS l2_eth_fees_per_day, median(multiIf(gas_price > 0, CAST((gas_price * t.receipt_gas_used) + receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000., NULL)) AS median_l2_eth_fees_per_tx, SUM(CAST(receipt_l1_fee, 'Nullable(Float64)') / 1000000000000000000.) AS l1_contrib_l2_eth_fees_per_day, SUM(CAST(gas_price * t.receipt_gas_used, 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_per_day, SUM(((CAST(receipt_l1_gas_used, 'Nullable(Float64)') * COALESCE(toInt64(NULL), receipt_l1_fee_scalar)) * CAST(receipt_l1_gas_price, 'Nullable(Float64)')) / 1000000000000000000.) AS l1_l1gas_contrib_l2_eth_fees_per_day, SUM(((CAST(receipt_l1_gas_used, 'Nullable(Float64)') * CAST(NULL, 'Nullable(Float64)')) * CAST(CAST(NULL, 'Nullable(Float64)'), 'Nullable(Float64)')) / 1000000000000000000.) AS l1_blobgas_contrib_l2_eth_fees_per_day, SUM(CAST(base_fee_per_gas * t.receipt_gas_used, 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_base_fee_per_day, SUM(CAST(gas_price - (base_fee_per_gas * t.receipt_gas_used), 'Nullable(Float64)') / 1000000000000000000.) AS l2_contrib_l2_eth_fees_priority_fee_per_day, SUM((16 * (length(replace(toString(unhex(input)), '\\0', '')) - 1)) + (4 * ((length(unhex(input)) - 1) - (length(replace(toString(unhex(input)), '\\0', '')) - 1)))) AS input_calldata_gas_l2_per_day, SUM(multiIf(gas_price > 0, (16 * (length(replace(toString(unhex(input)), '\\0', '')) - 1)) + (4 * ((length(unhex(input)) - 1) - (length(replace(toString(unhex(input)), '\\0', '')) - 1))), 0)) AS input_calldata_gas_user_txs_l2_per_day, SUM(receipt_l1_gas_used / 16) AS compressedtxsize_approx_l2_per_day, SUM(multiIf(gas_price > 0, receipt_l1_gas_used / 16, 0)) AS compressedtxsize_approx_user_txs_l2_per_day, SUM((CAST(receipt_l1_gas_price, 'Nullable(Float64)') / CAST(1000000000., 'Nullable(Float64)')) * CAST(receipt_l1_gas_used, 'Nullable(Float64)')) / SUM(CAST(receipt_l1_gas_used, 'Nullable(Float64)')) AS avg_l1_gas_price_on_l2, SUM(multiIf(gas_price > 0, CAST(t.receipt_gas_used * gas_price, 'Nullable(Float64)') / 1000000000., NULL)) / SUM(multiIf(gas_price > 0, t.receipt_gas_used, NULL)) AS avg_l2_gas_price, SUM(multiIf(gas_price > 0, (CAST(t.receipt_gas_used, 'Nullable(Float64)') * CAST(base_fee_per_gas, 'Nullable(Float64)')) / 1000000000., NULL)) / SUM(multiIf(gas_price > 0, t.receipt_gas_used, NULL)) AS base_fee_gwei, SUM(multiIf(gas_price = 0, 0, CAST(t.receipt_gas_used * receipt_l1_gas_price, 'Nullable(Float64)')) / 1000000000000000000.) AS equivalent_l1_tx_fee, AVG(multiIf(gas_price > 0, receipt_l1_fee_scalar, NULL)) AS avg_l1_fee_scalar, coalesce(AVG(multiIf(gas_price > 0, CAST(NULL, 'Nullable(Float64)'), NULL)), 0) AS avg_l1_blob_fee_scalar FROM fraxtal_transactions AS t INNER JOIN fraxtal_blocks AS b ON (t.block_number = b.block_number) AND (t.block_timestamp = b.block_timestamp) WHERE (block_timestamp >= DATE_TRUNC('day', now() - toIntervalDay(9999))) AND (b.block_timestamp >= DATE_TRUNC('day', now() - toIntervalDay(9999))) GROUP BY 1, 2, 3, 4. (UNKNOWN_IDENTIFIER) (version 24.2.2.16288 (official build))\n"
     ]
    }
   ],
   "source": [
    "for qn in query_names:\n",
    "        for mapping in chain_mappings_list:\n",
    "                chain_schema = mapping['schema_name']\n",
    "                display_name = mapping['display_name']\n",
    "                has_blob_fields = mapping['has_blob_fields']\n",
    "                # If we can do it programmatically from UI saved queries\n",
    "                # query = client.get_job(query_name)\n",
    "                # Read the SQL query from file\n",
    "                if has_blob_fields:\n",
    "                        qn=qn+ '_updated'\n",
    "                with open(os.path.join(sql_directory, f\"{qn}.sql\"), \"r\") as file:\n",
    "                        query = file.read()\n",
    "                print(qn + ' - ' + chain_schema)\n",
    "                dune_table_name = qn\n",
    "\n",
    "                #Pass in Params to the query\n",
    "                query = query.replace(\"@chain_db_name@\", chain_schema)\n",
    "                query = query.replace(\"@trailing_days@\", str(trailing_days))\n",
    "                query = query.replace(\"@block_time_sec@\", str(block_time_sec))\n",
    "                query = query.replace(\"@max_execution_secs@\", str(max_execution_secs))\n",
    "\n",
    "                if ~has_blob_fields:\n",
    "                        query = query.replace(\"receipt_l1_blob_base_fee_scalar\", 'cast(NULL as Nullable(Float64))')\n",
    "                        query = query.replace(\"receipt_l1_blob_base_fee\", 'cast(NULL as Nullable(Float64))')\n",
    "                        query = query.replace(\"receipt_l1_base_fee_scalar\", 'toInt64(NULL)')\n",
    "                # Execute the query\n",
    "                result_df = client.query_df(query)\n",
    "        #         # Write to csv\n",
    "        #         df.to_csv('outputs/chain_data/' + qn + '.csv', index=False)\n",
    "        #         # print(df.sample(5))\n",
    "        #         time.sleep(1)\n",
    "                \n",
    "                result_df['chain_raw'] = result_df['chain']\n",
    "                result_df['chain'] = result_df['chain'].replace(chain_mappings_dict)\n",
    "                unified_dfs.append(result_df)\n",
    "\n",
    "        write_df = pd.concat(unified_dfs)\n",
    "        write_df.to_csv('outputs/chain_data/' + dune_table_name + '.csv', index=False)\n",
    "        d.write_dune_api_from_pandas(write_df, dune_table_name,table_description = dune_table_name)\n",
    "        \n",
    "        # # # Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BQ Upload\n",
    "time.sleep(1)\n",
    "bqu.write_df_to_bq_table(write_df, table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
