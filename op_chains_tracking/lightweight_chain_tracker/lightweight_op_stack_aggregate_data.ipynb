{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See readme.md for ideal fields and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas pyarrow\n",
    "# ! pip install polars\n",
    "# ! pip install maturin\n",
    "# ! pip install cryo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../helper_functions'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import cryo\n",
    "import sys\n",
    "sys.path.append(\"../../helper_functions\")\n",
    "import web3py_utils as w3py\n",
    "sys.path.pop()\n",
    "# test adding cryo_cli python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test doing Degen Chain\n",
    "rpc_url = 'https://rpc.degen.tips'\n",
    "chain_name = 'degen'\n",
    "\n",
    "# Lyra\n",
    "# rpc_url = 'https://rpc.lyra.finance/'\n",
    "# chain_name = 'lyra'\n",
    "\n",
    "block_time_sec = 2\n",
    "###\n",
    "trailing_days = 0.25\n",
    "dry_run = False\n",
    "fields = ['blocks', 'txs']\n",
    "requests_per_second_max = 500 # -1 means ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intermediate Calc\n",
    "blocks_per_day = (60*60*24) / block_time_sec\n",
    "# print(blocks_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end: 7256567.0\n",
      "start: 7267367\n"
     ]
    }
   ],
   "source": [
    "# Init timestamps\n",
    "\n",
    "\n",
    "current_date_utc = datetime.utcnow().date()\n",
    "# Convert the current date to a Unix timestamp (remaining in UTC)\n",
    "current_timestamp_utc = datetime(current_date_utc.year, current_date_utc.month, current_date_utc.day, tzinfo=timezone.utc).timestamp()\n",
    "previous_date_utc = current_date_utc - timedelta(days=trailing_days)\n",
    "previous_timestamp_utc = datetime(previous_date_utc.year, previous_date_utc.month, previous_date_utc.day, tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "current_block = w3py.getLatestBlockNumber(rpc_url)\n",
    "previous_block = current_block - (trailing_days * blocks_per_day)\n",
    "\n",
    "print('end: ' + str(previous_block))\n",
    "print('start: ' + str(current_block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_timestamp = int(previous_timestamp_utc)\n",
    "end_timestamp = int(current_timestamp_utc)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mcryo parameters\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mversion\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m152a635\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdata\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdatatypes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mblocks, transactions\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mn=10,800 min=7,256,567 max=7,267,366 align=no reorg_buffer=0\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msource\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnetwork\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mnetwork_666666666\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mrpc url\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhttps://rpc.degen.tips\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax requests per second\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m500\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent requests\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m500\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent chunks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m4\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunk size\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m1,000\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks to collect\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m11 / 11\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput format\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mparquet\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput dir\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m/Users/michaelsilberling/Documents/GitHub/op-analytics/op_chains_tracking/lightweight_chain_tracker/outputs\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mreport file\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m$OUTPUT_DIR/.cryo/reports/2024-04-18_11-27-56.235469.json\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for blocks\u001b[0m\n",
      "\u001b[38;2;0;225;0m─────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtimestamp\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mauthor\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mextra_data\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mbase_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting blocks by: block_number\n",
      "\n",
      "other available columns: parent_hash, state_root, transactions_root, receipts_root, logs_bloom, total_difficulty, size\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for transactions\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_index\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnonce\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mfrom_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mto_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_binary\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mbinary\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_string\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mstring\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_f64\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mfloat64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37minput\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_limit\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_price\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_type\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_priority_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msuccess\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mbool\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_zero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_nonzero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting transactions by: block_number, transaction_index\n",
      "\n",
      "other available columns: n_rlp_bytes, block_hash, timestamp\n",
      "\n",
      "\n",
      "[dry run, exiting]\n"
     ]
    }
   ],
   "source": [
    "# Generate Command\n",
    "# if dry_run == 1:\n",
    "#     dry_txt = '--dry'\n",
    "# else:\n",
    "#     dry_txt = ''\n",
    "# if requests_per_second_max > -1:\n",
    "#     rps_txt = '--requests-per-second ' + str(requests_per_second_max)\n",
    "# else:\n",
    "#     rps_txt = ''\n",
    "\n",
    "# Fetch and save blocks data in JSON\n",
    "data = cryo.freeze(\n",
    "    ['txs', 'blocks'],\n",
    "    blocks=[str(previous_block) + \":\" + str(current_block)],\n",
    "    rpc=rpc_url,\n",
    "    output_dir=\"outputs/\",\n",
    "    file_format='parquet',\n",
    "    label=chain_name,\n",
    "    hex=True,\n",
    "    dry=dry_run,\n",
    "    requests_per_second=requests_per_second_max\n",
    ")\n",
    "# command = f\"cryo {fields} --rpc {rpc_url} --timestamps {start_timestamp}:{end_timestamp} --subdirs datatype --label {chain_name} {rps_txt} {dry_txt}\"\n",
    "# print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the command using subprocess.run and capture the output\n",
    "# result = subprocess.run(\n",
    "#     command, \n",
    "#     shell=True, \n",
    "#     stdout=subprocess.PIPE,  # Capture standard output\n",
    "#     stderr=subprocess.PIPE,  # Capture standard error\n",
    "#     text=True  # Capture output as text (Python 3.7+)\n",
    "# )\n",
    "\n",
    "# # Display the captured output\n",
    "# if result.returncode == 0:\n",
    "#     print(\"Command succeeded. Output:\")\n",
    "#     print(result.stdout)\n",
    "# else:\n",
    "#     print(\"Command failed. Error output:\")\n",
    "#     print(result.stderr)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.1521 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "# Print the elapsed time in seconds\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read parquet files\n",
    "txs = pl.scan_parquet('transactions__' + chain_name + '/*.parquet')\n",
    "blocks = pl.scan_parquet('blocks__' + chain_name + '/*.parquet')\n",
    "\n",
    "# Rename the 'gas_used' column to 'block_gas_used' in the 'blocks' DataFrame\n",
    "blocks = blocks.rename({\"gas_used\": \"block_gas_used\"})\n",
    "\n",
    "# Perform the join on 'block_number' and 'chain_id'\n",
    "joined_df = blocks.join(\n",
    "    txs,\n",
    "    on=[\"block_number\", \"chain_id\"],\n",
    "    how=\"inner\"  # You can specify the type of join you want (inner, outer, left, right)\n",
    ")\n",
    "\n",
    "# Convert Unix timestamp to datetime and create a new column 'timestamp_dt'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.from_epoch(\"timestamp\", time_unit=\"s\").alias(\"timestamp_dt\")\n",
    ")\n",
    "\n",
    "# Truncate the 'timestamp_dt' column to the day and create a new column 'timestamp_date'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.col(\"timestamp_dt\").dt.truncate(\"1d\").alias(\"timestamp_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(blocks.schema)\n",
    "# print(txs.schema)\n",
    "print(joined_df.schema)\n",
    "\n",
    "#test output\n",
    "joined_pd = joined_df.collect().to_pandas()\n",
    "joined_pd.tail(5)\n",
    "\n",
    "print('num blocks: ' + str(joined_pd['block_number'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference list of consecutive block numbers\n",
    "reference_block_numbers = list(range(joined_pd['block_number'].min(), joined_pd['block_number'].max() + 1))\n",
    "\n",
    "# Find the missing block numbers\n",
    "missing_block_numbers = set(reference_block_numbers) - set(joined_pd['block_number'])\n",
    "\n",
    "print(\"Missing block numbers:\", missing_block_numbers)\n",
    "\n",
    "# Convert the missing_block_numbers set to a list and sort it\n",
    "missing_block_numbers_list = sorted(list(missing_block_numbers))\n",
    "is_consecutive = all(missing_block_numbers_list[i] == missing_block_numbers_list[i - 1] + 1 for i in range(1, len(missing_block_numbers_list)))\n",
    "\n",
    "if is_consecutive:\n",
    "    print(\"The missing block numbers are consecutive.\")\n",
    "else:\n",
    "    print(\"The missing block numbers are not consecutive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'joined_df' with the required columns\n",
    "\n",
    "result_df = joined_df.group_by([pl.col(\"timestamp_date\"), pl.col(\"chain_id\")]).agg(\n",
    "    num_blocks=pl.col(\"block_number\").n_unique(),\n",
    "    min_block_number=pl.col(\"block_number\").min(),\n",
    "    max_block_number=pl.col(\"block_number\").max(),\n",
    "    min_block_time=pl.col(\"timestamp\").min(),\n",
    "    max_block_time=pl.col(\"timestamp\").max(),\n",
    "\n",
    "    num_user_transactions=\n",
    "        pl.when(pl.col(\"gas_price\") > 0).then(pl.col(\"transaction_hash\")).count(),\n",
    "    num_success_user_transactions=\n",
    "        pl.when((pl.col(\"gas_price\") > 0) & pl.col(\"success\")).then(pl.col(\"transaction_hash\")).count(),\n",
    "    num_senders=pl.col(\"from_address\").filter(pl.col(\"gas_price\") > 0).n_unique(),\n",
    "\n",
    "    total_gas_used=pl.col(\"gas_used\").sum(),\n",
    "    user_gas_used=pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum(),\n",
    "    total_gas_used_per_block = pl.col(\"gas_used\").sum() / pl.col(\"block_number\").n_unique(),\n",
    "    user_gas_used_per_block = pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum() / pl.col(\"block_number\").n_unique(),\n",
    "    \n",
    "    l2_fees_base_fees_eth=(pl.col(\"base_fee_per_gas\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "    l2_fees_priority_fees_eth=pl.when(pl.col(\"gas_price\") > 0).then((pl.col(\"gas_price\") - pl.col(\"base_fee_per_gas\")) * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "    l2_fees_total_fees_eth=(pl.col(\"gas_price\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute and turn to pandas\n",
    "result_df = result_df.collect().to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "result_df = result_df[result_df['min_block_time']>= start_timestamp] #seems like 1 block before gets pulled. yolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df['min_block_time_dt'] = pd.to_datetime(result_df['min_block_time'], unit='s')\n",
    "result_df['max_block_time_dt'] = pd.to_datetime(result_df['max_block_time'], unit='s')\n",
    "display(result_df.sort_values(by='timestamp_date',ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
