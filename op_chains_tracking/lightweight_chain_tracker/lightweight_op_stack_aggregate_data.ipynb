{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See readme.md for ideal fields and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas pyarrow\n",
    "# ! pip install polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "# test adding cryo_cli python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init timestamps\n",
    "trailing_days = 7\n",
    "\n",
    "current_date_utc = datetime.utcnow().date()\n",
    "# Convert the current date to a Unix timestamp (remaining in UTC)\n",
    "current_timestamp_utc = datetime(current_date_utc.year, current_date_utc.month, current_date_utc.day, tzinfo=timezone.utc).timestamp()\n",
    "previous_date_utc = current_date_utc - timedelta(days=trailing_days)\n",
    "previous_timestamp_utc = datetime(previous_date_utc.year, previous_date_utc.month, previous_date_utc.day, tzinfo=timezone.utc).timestamp()\n",
    "\n",
    "print('end: ' + str(current_date_utc))\n",
    "print('start: ' + str(previous_date_utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test doing Lyra\n",
    "\n",
    "fields = 'blocks txs'# traces'\n",
    "rpc_url = 'https://rpc.lyra.finance/'\n",
    "chain_name = 'lyra'\n",
    "start_timestamp = int(previous_timestamp_utc)\n",
    "end_timestamp = int(current_timestamp_utc)\n",
    "\n",
    "dry_run = 0\n",
    "requests_per_second_max = 500 # -1 means ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Command\n",
    "if dry_run == 1:\n",
    "    dry_txt = '--dry'\n",
    "else:\n",
    "    dry_txt = ''\n",
    "if requests_per_second_max > -1:\n",
    "    rps_txt = '--requests-per-second ' + str(requests_per_second_max)\n",
    "else:\n",
    "    rps_txt = ''\n",
    "\n",
    "command = f\"cryo {fields} --rpc {rpc_url} --timestamps {start_timestamp}:{end_timestamp} --subdirs datatype --label {chain_name} {rps_txt} {dry_txt}\"\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Run the command using subprocess.run and capture the output\n",
    "result = subprocess.run(\n",
    "    command, \n",
    "    shell=True, \n",
    "    stdout=subprocess.PIPE,  # Capture standard output\n",
    "    stderr=subprocess.PIPE,  # Capture standard error\n",
    "    text=True  # Capture output as text (Python 3.7+)\n",
    ")\n",
    "\n",
    "# Display the captured output\n",
    "if result.returncode == 0:\n",
    "    print(\"Command succeeded. Output:\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Command failed. Error output:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "# Print the elapsed time in seconds\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read parquet files\n",
    "txs = pl.scan_parquet('transactions__' + chain_name + '/*.parquet')\n",
    "blocks = pl.scan_parquet('blocks__' + chain_name + '/*.parquet')\n",
    "\n",
    "# Rename the 'gas_used' column to 'block_gas_used' in the 'blocks' DataFrame\n",
    "blocks = blocks.rename({\"gas_used\": \"block_gas_used\"})\n",
    "\n",
    "# Perform the join on 'block_number' and 'chain_id'\n",
    "joined_df = blocks.join(\n",
    "    txs,\n",
    "    on=[\"block_number\", \"chain_id\"],\n",
    "    how=\"inner\"  # You can specify the type of join you want (inner, outer, left, right)\n",
    ")\n",
    "\n",
    "# Convert Unix timestamp to datetime and create a new column 'timestamp_dt'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.from_epoch(\"timestamp\", time_unit=\"s\").alias(\"timestamp_dt\")\n",
    ")\n",
    "\n",
    "# Truncate the 'timestamp_dt' column to the day and create a new column 'timestamp_date'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.col(\"timestamp_dt\").dt.truncate(\"1d\").alias(\"timestamp_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(blocks.schema)\n",
    "# print(txs.schema)\n",
    "print(joined_df.schema)\n",
    "\n",
    "#test output\n",
    "joined_pd = joined_df.collect().to_pandas()\n",
    "joined_pd.tail(5)\n",
    "\n",
    "print('num blocks: ' + str(joined_pd['block_number'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference list of consecutive block numbers\n",
    "reference_block_numbers = list(range(joined_pd['block_number'].min(), joined_pd['block_number'].max() + 1))\n",
    "\n",
    "# Find the missing block numbers\n",
    "missing_block_numbers = set(reference_block_numbers) - set(joined_pd['block_number'])\n",
    "\n",
    "print(\"Missing block numbers:\", missing_block_numbers)\n",
    "\n",
    "# Convert the missing_block_numbers set to a list and sort it\n",
    "missing_block_numbers_list = sorted(list(missing_block_numbers))\n",
    "is_consecutive = all(missing_block_numbers_list[i] == missing_block_numbers_list[i - 1] + 1 for i in range(1, len(missing_block_numbers_list)))\n",
    "\n",
    "if is_consecutive:\n",
    "    print(\"The missing block numbers are consecutive.\")\n",
    "else:\n",
    "    print(\"The missing block numbers are not consecutive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'joined_df' with the required columns\n",
    "\n",
    "result_df = joined_df.group_by([pl.col(\"timestamp_date\"), pl.col(\"chain_id\")]).agg(\n",
    "    num_blocks=pl.col(\"block_number\").n_unique(),\n",
    "    min_block_number=pl.col(\"block_number\").min(),\n",
    "    max_block_number=pl.col(\"block_number\").max(),\n",
    "    min_block_time=pl.col(\"timestamp\").min(),\n",
    "    max_block_time=pl.col(\"timestamp\").max(),\n",
    "\n",
    "    num_user_transactions=\n",
    "        pl.when(pl.col(\"gas_price\") > 0).then(pl.col(\"transaction_hash\")).count(),\n",
    "    num_success_user_transactions=\n",
    "        pl.when((pl.col(\"gas_price\") > 0) & pl.col(\"success\")).then(pl.col(\"transaction_hash\")).count(),\n",
    "    num_senders=pl.col(\"from_address\").filter(pl.col(\"gas_price\") > 0).n_unique(),\n",
    "\n",
    "    total_gas_used=pl.col(\"gas_used\").sum(),\n",
    "    user_gas_used=pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum(),\n",
    "    total_gas_used_per_block = pl.col(\"gas_used\").sum() / pl.col(\"block_number\").n_unique(),\n",
    "    user_gas_used_per_block = pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum() / pl.col(\"block_number\").n_unique(),\n",
    "    \n",
    "    l2_fees_base_fees_eth=(pl.col(\"base_fee_per_gas\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "    l2_fees_priority_fees_eth=pl.when(pl.col(\"gas_price\") > 0).then((pl.col(\"gas_price\") - pl.col(\"base_fee_per_gas\")) * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "    l2_fees_total_fees_eth=(pl.col(\"gas_price\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    ")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute and turn to pandas\n",
    "result_df = result_df.collect().to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "result_df = result_df[result_df['min_block_time']>= start_timestamp] #seems like 1 block before gets pulled. yolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df['min_block_time_dt'] = pd.to_datetime(result_df['min_block_time'], unit='s')\n",
    "result_df['max_block_time_dt'] = pd.to_datetime(result_df['max_block_time'], unit='s')\n",
    "display(result_df.sort_values(by='timestamp_date',ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
