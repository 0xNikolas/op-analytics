{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See readme.md for ideal fields and descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can do installs here when conde env is activated\n",
    "# ! pip install pandas pyarrow\n",
    "# ! pip install polars\n",
    "# ! pip install maturin\n",
    "# ! pip install cryo\n",
    "# ! pip install web3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelsilberling/opt/anaconda3/envs/cryo-env/lib/python3.8/site-packages/eth_utils/network.py:61: UserWarning: Network 345 with name 'Yooldo Verse Mainnet' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  networks = initialize_network_objects()\n",
      "/Users/michaelsilberling/opt/anaconda3/envs/cryo-env/lib/python3.8/site-packages/eth_utils/network.py:61: UserWarning: Network 12611 with name 'Astar zkEVM' does not have a valid ChainId. eth-typing should be updated with the latest networks.\n",
      "  networks = initialize_network_objects()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import cryo\n",
    "import sys\n",
    "sys.path.append(\"../../helper_functions\")\n",
    "import web3py_utils as w3py\n",
    "import os_utils as osu\n",
    "sys.path.pop()\n",
    "import polars as pl\n",
    "# test adding cryo_cli python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder cleared.\n"
     ]
    }
   ],
   "source": [
    "output_directory = 'cryo_outputs/'\n",
    "# clear out\n",
    "osu.clear_folder(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "redstone = {\n",
    "        'rpc_url': 'https://rpc.redstonechain.com',\n",
    "        'chain_name': 'redstone',\n",
    "        'block_time_sec': 2,\n",
    "        'block_time_buffer': 0,\n",
    "        'stack': 'op'\n",
    "        }\n",
    "# Lyra\n",
    "lyra = {\n",
    "        'rpc_url': 'https://rpc.lyra.finance/',\n",
    "        'chain_name': 'lyra',\n",
    "        'block_time_sec': 2,\n",
    "        'block_time_buffer': 0,\n",
    "        'stack': 'op'\n",
    "        }\n",
    "degen = {\n",
    "        'rpc_url': 'https://rpc.degen.tips',\n",
    "        'chain_name': 'degen',\n",
    "        'block_time_sec': 0.383, #Note: Arb Stack not deterministic\n",
    "        'block_time_buffer': 0.25,\n",
    "        'stack': 'arb'\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick Chain\n",
    "config_chain = degen\n",
    "datasets = ['txs', 'logs', 'blocks']\n",
    "###\n",
    "whole_day_only = True\n",
    "trailing_days = 0.25\n",
    "dry_run = False\n",
    "requests_per_second_max = 500 # -1 means ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intermediate Calc\n",
    "rpc_url = config_chain['rpc_url']\n",
    "stack = config_chain['stack']\n",
    "chain_name = config_chain['chain_name']\n",
    "# block_time_sec = config_chain['block_time_sec']\n",
    "# block_time_buffer = config_chain['block_time_buffer']\n",
    "\n",
    "# blocks_per_day = (60*60*24) / block_time_sec\n",
    "# blocks_per_day_lo = (60*60*24) / (block_time_sec+block_time_buffer)\n",
    "# if block_time_sec-block_time_buffer > 0:\n",
    "#         blocks_per_day_hi = (60*60*24) / (block_time_sec-block_time_buffer)\n",
    "# else:\n",
    "#         blocks_per_day_hi = (60*60*24) / 0.01\n",
    "\n",
    "# print(blocks_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day fraction :0.006180433379629631\n",
      "2024-05-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Init timestamps\n",
    "\n",
    "# Get the current time in UTC\n",
    "current_time_utc = datetime.utcnow()\n",
    "# print(current_time_utc)\n",
    "\n",
    "# If only whole days then shift the ending time to the start of the day\n",
    "if whole_day_only:\n",
    "        current_date_utc = datetime.combine(datetime.utcnow().date(), datetime.min.time())\n",
    "        time_difference = current_time_utc - current_date_utc\n",
    "        difference_days_fraction = time_difference.total_seconds() / (24 * 3600)  # There are 86400 seconds in a day\n",
    "else: \n",
    "        current_date_utc = current_time_utc\n",
    "        difference_days_fraction = 0\n",
    "print('day fraction :' + str(difference_days_fraction))\n",
    "\n",
    "print(current_date_utc)\n",
    "starting_date_utc = current_date_utc - timedelta(days=trailing_days)\n",
    "\n",
    "current_block = w3py.getLatestBlockNumber(rpc_url)\n",
    "\n",
    "# ending_block = int( current_block - (difference_days_fraction * blocks_per_day_lo) )\n",
    "# starting_block = int( ending_block - (trailing_days * blocks_per_day_hi) )\n",
    "\n",
    "# print('current: ' + str(int(current_block)))\n",
    "# print('end: ' + str(int(ending_block)))\n",
    "# print('start: ' + str(int(starting_block)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-09 21:00:00\n",
      "2024-05-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(starting_date_utc)\n",
    "print(current_date_utc)\n",
    "start_timestamp = int(starting_date_utc.timestamp())\n",
    "end_timestamp = int(current_date_utc.timestamp())\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37mcryo parameters\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mversion\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m152a635\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdata\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdatatypes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mblocks, transactions, logs\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mn=11 min=14,581,785 max=14,581,795 align=no reorg_buffer=0\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msource\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnetwork\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mnetwork_666666666\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mrpc url\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhttps://rpc.degen.tips\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax requests per second\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m500\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent requests\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m500\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent chunks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m4\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37minner request size\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m1\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunk size\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m11\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks to collect\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m2 / 2\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput format\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mparquet\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput dir\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m/Users/michaelsilberling/Documents/GitHub/op-analytics/op_chains_tracking/lightweight_chain_tracker/cryo_outputs\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mreport file\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m$OUTPUT_DIR/.cryo/reports/2024-05-09_20-08-59.354869.json\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for blocks\u001b[0m\n",
      "\u001b[38;2;0;225;0m─────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtimestamp\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mauthor\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mextra_data\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mbase_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting blocks by: block_number\n",
      "\n",
      "other available columns: parent_hash, state_root, transactions_root, receipts_root, logs_bloom, total_difficulty, size\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for transactions\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_index\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnonce\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mfrom_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mto_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_binary\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mbinary\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_string\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mstring\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mvalue_f64\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mfloat64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37minput\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_limit\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_price\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_type\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_priority_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msuccess\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mbool\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_zero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_nonzero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting transactions by: block_number, transaction_index\n",
      "\n",
      "other available columns: n_rlp_bytes, block_hash, timestamp\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for logs\u001b[0m\n",
      "\u001b[38;2;0;225;0m────────��──────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_index\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mlog_index\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37maddress\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtopic0\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtopic1\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtopic2\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtopic3\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdata\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting logs by: block_number, log_index\n",
      "\n",
      "other available columns: block_hash\n",
      "\n",
      "\n",
      "\u001b[1;37mcollecting data\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────\u001b[0m\n",
      "started at 2024-05-09 20:08:59.354\n",
      "   done at 2024-05-09 20:08:59.981\n",
      "\n",
      "\n",
      "\u001b[1;37mcollection summary\u001b[0m\n",
      "\u001b[38;2;0;225;0m──────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtotal duration\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m0.627 seconds\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtotal chunks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m2\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks errored\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m  0 / 2 (0.0%)\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks skipped\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m  0 / 2 (0.0%)\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks collected\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m2 / 2 (100.0%)\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks collected\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m11\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per second\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m    17.5\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per minute\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m 1,052.5\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per hour\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m  63,151.8\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per day\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m1,515,642.0\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mrows written\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m261\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Fetch and save data in JSON\n",
    "data = cryo.freeze(\n",
    "    datasets,\n",
    "    # blocks=[str(starting_block) + \":\" + str(ending_block)],\n",
    "    timestamps=[str(start_timestamp) + \":\" + str(end_timestamp)],\n",
    "    rpc=rpc_url,\n",
    "    output_dir= output_directory,\n",
    "    file_format='parquet',\n",
    "    label=chain_name,\n",
    "    hex=True,\n",
    "    dry=dry_run,\n",
    "    requests_per_second=requests_per_second_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.6834 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "# Print the elapsed time in seconds\n",
    "print(f\"Elapsed time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move this to a cryo_utils eventually\n",
    "\n",
    "def load_parquet_files(chain_name, data_type_name, data_directory):\n",
    "    pattern = f\"*{data_type_name}__{chain_name}*.parquet\"\n",
    "    file_paths = glob.glob(os.path.join(data_directory, pattern))\n",
    "    \n",
    "    if file_paths:\n",
    "        df = pl.scan_parquet(file_paths)\n",
    "        # Further processing can go here, for example:\n",
    "        # df = df.filter(pl.col(\"some_column\") > 0)\n",
    "        return df.collect()  # Collecting after all transformations\n",
    "    else:\n",
    "        print(\"No files found matching the pattern.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['block_number', 'transaction_index', 'transaction_hash', 'nonce', 'from_address', 'to_address', 'value_binary', 'value_string', 'value_f64', 'input', 'gas_limit', 'gas_used', 'gas_price', 'transaction_type', 'max_priority_fee_per_gas', 'max_fee_per_gas', 'success', 'n_input_bytes', 'n_input_zero_bytes', 'n_input_nonzero_bytes', 'chain_id']\n",
      "['block_hash', 'author', 'block_number', 'block_gas_used', 'extra_data', 'timestamp', 'base_fee_per_gas', 'chain_id']\n",
      "['block_number', 'transaction_index', 'log_index', 'transaction_hash', 'address', 'topic0', 'topic1', 'topic2', 'topic3', 'data', 'chain_id']\n"
     ]
    }
   ],
   "source": [
    "# # Read parquet files\n",
    "blocks = load_parquet_files(chain_name, 'blocks', output_directory)\n",
    "txs = load_parquet_files(chain_name, 'transactions', output_directory)\n",
    "logs = load_parquet_files(chain_name, 'logs', output_directory)\n",
    "\n",
    "# Rename the 'gas_used' column to 'block_gas_used' in the 'blocks' DataFrame\n",
    "blocks = blocks.rename({\"gas_used\": \"block_gas_used\"})\n",
    "print(txs.columns)\n",
    "print(blocks.columns)\n",
    "print(logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the exclude_topics from CSV\n",
    "non_app_methods_df = pl.read_csv(\"../inputs/non_app_methods.csv\")\n",
    "# print(non_app_methods_df)\n",
    "exclude_topics = non_app_methods_df.filter(non_app_methods_df['type'] == \"topic0\")[\"method_id\"].to_list()\n",
    "# print(exclude_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by block_number, transaction_hash, and chain_id and count rows\n",
    "logs_agg = (\n",
    "    logs.group_by([pl.col(\"block_number\"), pl.col(\"transaction_hash\"), pl.col(\"chain_id\")])\n",
    "    .agg(\n",
    "        num_event_logs = pl.col(\"topic0\").count(),\n",
    "        num_app_event_logs = pl.col(\"topic0\").filter(~pl.col(\"topic0\").is_in(exclude_topics)).count()\n",
    "    )\n",
    ")\n",
    "# logs_agg[['transaction_hash','num_event_logs','num_app_event_logs']].glimpse()\n",
    "# logs_agg.filter(pl.col(\"num_event_logs\") != pl.col(\"num_app_event_logs\")).glimpse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform the join on 'block_number' and 'chain_id'\n",
    "joined_df = blocks.join(\n",
    "    txs,\n",
    "    on=[\"block_number\", \"chain_id\"],\n",
    "    how=\"inner\"  # You can specify the type of join you want (inner, outer, left, right)\n",
    ")\n",
    "joined_df = joined_df.join(\n",
    "    logs_agg,\n",
    "    on=[\"block_number\", \"chain_id\", \"transaction_hash\"],\n",
    "    how=\"left\"  # You can specify the type of join you want (inner, outer, left, right)\n",
    ")\n",
    "# Convert Unix timestamp to datetime and create a new column 'timestamp_dt'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.from_epoch(\"timestamp\", time_unit=\"s\").alias(\"timestamp_dt\")\n",
    ")\n",
    "\n",
    "# Truncate the 'timestamp_dt' column to the day and create a new column 'timestamp_date'\n",
    "joined_df = joined_df.with_columns(\n",
    "    pl.col(\"timestamp_dt\").dt.truncate(\"1d\").alias(\"timestamp_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715299736\n",
      "1715299734\n",
      "['block_hash', 'author', 'block_number', 'block_gas_used', 'extra_data', 'timestamp', 'base_fee_per_gas', 'chain_id', 'transaction_index', 'transaction_hash', 'nonce', 'from_address', 'to_address', 'value_binary', 'value_string', 'value_f64', 'input', 'gas_limit', 'gas_used', 'gas_price', 'transaction_type', 'max_priority_fee_per_gas', 'max_fee_per_gas', 'success', 'n_input_bytes', 'n_input_zero_bytes', 'n_input_nonzero_bytes', 'num_event_logs', 'num_app_event_logs', 'timestamp_dt', 'timestamp_date']\n",
      "1715302800\n",
      "1715313600\n",
      "shape: (116, 2)\n",
      "┌────────────┬─────────────────────┐\n",
      "│ timestamp  ┆ timestamp_dt        │\n",
      "│ ---        ┆ ---                 │\n",
      "│ u32        ┆ datetime[μs]        │\n",
      "╞════════════╪═════════════════════╡\n",
      "│ 1715299734 ┆ 2024-05-10 00:08:54 │\n",
      "│ 1715299734 ┆ 2024-05-10 00:08:54 │\n",
      "│ 1715299734 ┆ 2024-05-10 00:08:54 │\n",
      "│ 1715299734 ┆ 2024-05-10 00:08:54 │\n",
      "│ 1715299734 ┆ 2024-05-10 00:08:54 │\n",
      "│ …          ┆ …                   │\n",
      "│ 1715299736 ┆ 2024-05-10 00:08:56 │\n",
      "│ 1715299736 ┆ 2024-05-10 00:08:56 │\n",
      "│ 1715299736 ┆ 2024-05-10 00:08:56 │\n",
      "│ 1715299736 ┆ 2024-05-10 00:08:56 │\n",
      "│ 1715299736 ┆ 2024-05-10 00:08:56 │\n",
      "└────────────┴─────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(joined_df['timestamp'].max())\n",
    "print(joined_df['timestamp'].min())\n",
    "\n",
    "print(joined_df.columns)\n",
    "print(start_timestamp)\n",
    "print(end_timestamp)\n",
    "print(joined_df[['timestamp','timestamp_dt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('block_hash', String), ('author', String), ('block_number', UInt32), ('block_gas_used', UInt64), ('extra_data', String), ('timestamp', UInt32), ('base_fee_per_gas', UInt64), ('chain_id', UInt64), ('transaction_index', UInt64), ('transaction_hash', String), ('nonce', UInt64), ('from_address', String), ('to_address', String), ('value_binary', String), ('value_string', String), ('value_f64', Float64), ('input', String), ('gas_limit', UInt64), ('gas_used', UInt64), ('gas_price', UInt64), ('transaction_type', UInt32), ('max_priority_fee_per_gas', UInt64), ('max_fee_per_gas', UInt64), ('success', Boolean), ('n_input_bytes', UInt32), ('n_input_zero_bytes', UInt32), ('n_input_nonzero_bytes', UInt32), ('num_event_logs', UInt32), ('num_app_event_logs', UInt32), ('timestamp_dt', Datetime(time_unit='us', time_zone=None)), ('timestamp_date', Datetime(time_unit='us', time_zone=None))])\n",
      "<class 'polars.dataframe.frame.DataFrame'>\n",
      "num blocks: 11\n"
     ]
    }
   ],
   "source": [
    "# print(blocks.schema)\n",
    "# print(txs.schema)\n",
    "print(joined_df.schema)\n",
    "print(type(joined_df))\n",
    "\n",
    "#test output\n",
    "joined_pd = joined_df.to_pandas()\n",
    "# print(joined_pd.tail(5))\n",
    "\n",
    "print('num blocks: ' + str(joined_pd['block_number'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'joined_df' with the required columns\n",
    "\n",
    "if stack == 'op':\n",
    "        l2_gas_used = pl.col(\"gas_used\")\n",
    "        l1_gas_used = pl.col(\"l1_gas_used\")\n",
    "elif stack == 'arb':\n",
    "        # Need to add columns to cryo\n",
    "        l2_gas_used = pl.col(\"gas_used\") - pl.col(\"gas_used_for_l1\")\n",
    "        l1_gas_used = pl.col(\"gas_used_for_l1\")\n",
    "else:\n",
    "        l2_gas_used = pl.col(\"gas_used\")\n",
    "        l1_gas_used = pl.col(\"gas_used\") - pl.col(\"gas_used\")\n",
    "\n",
    "result_df = joined_df.group_by([pl.col(\"timestamp_date\"), pl.col(\"chain_id\")]).agg( # .filter( (pl.col(\"timestamp_dt\") >= start_timestamp) & (pl.col(\"timestamp_dt\") < end_timestamp) ) \\\n",
    "                num_blocks=pl.col(\"block_number\").n_unique(),\n",
    "                min_block_number=pl.col(\"block_number\").min(),\n",
    "                max_block_number=pl.col(\"block_number\").max(),\n",
    "                min_block_time=pl.col(\"timestamp\").min(),\n",
    "                max_block_time=pl.col(\"timestamp\").max(),\n",
    "\n",
    "                num_user_transactions=\n",
    "                pl.when(pl.col(\"gas_price\") > 0).then(pl.col(\"transaction_hash\")).count(),\n",
    "                num_success_user_transactions=\n",
    "                pl.when((pl.col(\"gas_price\") > 0) & pl.col(\"success\")).then(pl.col(\"transaction_hash\")).count(),\n",
    "                num_success_event_transactions=\n",
    "                pl.when((pl.col(\"gas_price\") > 0) & pl.col(\"success\") & (pl.col(\"num_event_logs\") > 0)).then(pl.col(\"transaction_hash\")).count(),\n",
    "                num_success_qualified_transactions=\n",
    "                pl.when((pl.col(\"gas_price\") > 0) & pl.col(\"success\") & (pl.col(\"num_app_event_logs\") > 0)).then(pl.col(\"transaction_hash\")).count(),\n",
    "                num_senders=pl.col(\"from_address\").filter(pl.col(\"gas_price\") > 0).n_unique(),\n",
    "\n",
    "                total_gas_used=pl.col(\"gas_used\").sum(),\n",
    "                user_gas_used=pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum(),\n",
    "                total_gas_used_per_block = pl.col(\"gas_used\").sum() / pl.col(\"block_number\").n_unique(),\n",
    "                user_gas_used_per_block = pl.col(\"gas_used\").filter(pl.col(\"gas_price\") > 0).sum() / pl.col(\"block_number\").n_unique(),\n",
    "\n",
    "                # l2_fees_base_fees_eth=( (pl.col(\"gas_price\") - pl.col(\"max_priority_fee_per_gas\")) * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "                # l2_fees_priority_fees_eth=pl.when(pl.col(\"gas_price\") > 0).then(pl.col(\"max_priority_fee_per_gas\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "                # l2_fees_total_fees_eth=(pl.col(\"gas_price\") * pl.col(\"gas_used\")).sum() / 1e18,\n",
    "\n",
    "                avg_l2_base_fee_gwei=( (pl.col(\"gas_price\") - pl.col(\"max_priority_fee_per_gas\")) * pl.col(\"gas_used\")).sum()\n",
    "                                        / pl.col(\"gas_used\").sum() /1e9,\n",
    "                avg_l2_priority_fee_gwei=pl.when(pl.col(\"gas_price\") > 0).then((pl.col(\"max_priority_fee_per_gas\")) * pl.col(\"gas_used\")).sum()\n",
    "                                        / pl.col(\"gas_used\").sum() /1e9,\n",
    "        )\n",
    "# timestamp formats\n",
    "# result_df = result_df.with_columns([\n",
    "#     pl.date_from_epoch_seconds(pl.col(\"min_block_time\")).alias(\"min_block_time_dt\"),\n",
    "#     pl.date_from_epoch_seconds(pl.col(\"max_block_time\")).alias(\"max_block_time_dt\")\n",
    "# ])\n",
    "\n",
    "result_df = result_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f\"data_outputs/{chain_name}_{start_timestamp}_{end_timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "# result_df = result_df[ (result_df['min_block_time']>= start_timestamp ) & (result_df['min_block_time']<= end_timestamp ) ]\n",
    "#seems like 1 block before gets pulled. yolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_date</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>num_blocks</th>\n",
       "      <th>min_block_number</th>\n",
       "      <th>max_block_number</th>\n",
       "      <th>min_block_time</th>\n",
       "      <th>max_block_time</th>\n",
       "      <th>num_user_transactions</th>\n",
       "      <th>num_success_user_transactions</th>\n",
       "      <th>num_success_event_transactions</th>\n",
       "      <th>num_success_qualified_transactions</th>\n",
       "      <th>num_senders</th>\n",
       "      <th>total_gas_used</th>\n",
       "      <th>user_gas_used</th>\n",
       "      <th>total_gas_used_per_block</th>\n",
       "      <th>user_gas_used_per_block</th>\n",
       "      <th>avg_l2_base_fee_gwei</th>\n",
       "      <th>avg_l2_priority_fee_gwei</th>\n",
       "      <th>min_block_time_dt</th>\n",
       "      <th>max_block_time_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-10</td>\n",
       "      <td>666666666</td>\n",
       "      <td>11</td>\n",
       "      <td>14581785</td>\n",
       "      <td>14581795</td>\n",
       "      <td>1715299734</td>\n",
       "      <td>1715299736</td>\n",
       "      <td>105</td>\n",
       "      <td>83</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>21875245</td>\n",
       "      <td>21875245</td>\n",
       "      <td>1.988659e+06</td>\n",
       "      <td>1.988659e+06</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.652334</td>\n",
       "      <td>2024-05-10 00:08:54</td>\n",
       "      <td>2024-05-10 00:08:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp_date   chain_id  num_blocks  min_block_number  max_block_number  \\\n",
       "0     2024-05-10  666666666          11          14581785          14581795   \n",
       "\n",
       "   min_block_time  max_block_time  num_user_transactions  \\\n",
       "0      1715299734      1715299736                    105   \n",
       "\n",
       "   num_success_user_transactions  num_success_event_transactions  \\\n",
       "0                             83                              72   \n",
       "\n",
       "   num_success_qualified_transactions  num_senders  total_gas_used  \\\n",
       "0                                  72           76        21875245   \n",
       "\n",
       "   user_gas_used  total_gas_used_per_block  user_gas_used_per_block  \\\n",
       "0       21875245              1.988659e+06             1.988659e+06   \n",
       "\n",
       "   avg_l2_base_fee_gwei  avg_l2_priority_fee_gwei   min_block_time_dt  \\\n",
       "0              0.029952                  0.652334 2024-05-10 00:08:54   \n",
       "\n",
       "    max_block_time_dt  \n",
       "0 2024-05-10 00:08:56  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df['min_block_time_dt'] = pd.to_datetime(result_df['min_block_time'], unit='s')\n",
    "result_df['max_block_time_dt'] = pd.to_datetime(result_df['max_block_time'], unit='s')\n",
    "display(result_df.sort_values(by='timestamp_date',ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
