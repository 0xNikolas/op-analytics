{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffefb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta, date\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../helper-functions')\n",
    "import defillama_utils as dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc56e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-07\n"
     ]
    }
   ],
   "source": [
    "# date ranges to build charts for\n",
    "drange = [0, 1, 7, 30, 90, 180, 365]\n",
    "# Do we count net flows marked at the lastest token price (1) or the price on each day (0)\n",
    "# By default, we opt to 1, so that price movement isn't accidentally counted as + or - flow remainder\n",
    "mark_at_latest_price = 1 #some errors with missing token prices we need to find solves for first\n",
    "\n",
    "trailing_num_days = max(drange)\n",
    "# print(trailing_num_days)\n",
    "\n",
    "start_date = date.today()-timedelta(days=trailing_num_days +1)\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b8d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelsilberling/Documents/GitHub/op-analytics/value_locked_flows/../helper-functions/defillama_utils.py:293: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protocols['parentProtocol'] = protocols['parentProtocol'].combine_first(protocols['name'])\n",
      "/Users/michaelsilberling/Documents/GitHub/op-analytics/value_locked_flows/../helper-functions/defillama_utils.py:295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  protocols['chainTvls'] = protocols['chainTvls'].apply(lambda x: list(x.keys()) )\n"
     ]
    }
   ],
   "source": [
    "#get all apps > 5 m tvl\n",
    "min_tvl = 5_000_000\n",
    "\n",
    "# if TVL by token is not available, do we fallback on raw TVL (sensitive to token prices)?\n",
    "is_fallback_on_raw_tvl = True#False\n",
    "\n",
    "df_df = dfl.get_all_protocol_tvls_by_chain_and_token(min_tvl, is_fallback_on_raw_tvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3254fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>token</th>\n",
       "      <th>token_value</th>\n",
       "      <th>usd_value</th>\n",
       "      <th>total_app_tvl</th>\n",
       "      <th>protocol</th>\n",
       "      <th>slug</th>\n",
       "      <th>chain</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>parent_protocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-19 23:00:00</td>\n",
       "      <td>WETH</td>\n",
       "      <td>2272.26688</td>\n",
       "      <td>1.484681e+06</td>\n",
       "      <td>1.484681e+06</td>\n",
       "      <td>lido</td>\n",
       "      <td>lido</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>Lido</td>\n",
       "      <td>Lido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-19 23:00:00</td>\n",
       "      <td>MATIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.484681e+06</td>\n",
       "      <td>lido</td>\n",
       "      <td>lido</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>Lido</td>\n",
       "      <td>Lido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-20 23:00:00</td>\n",
       "      <td>WETH</td>\n",
       "      <td>4140.77143</td>\n",
       "      <td>2.697598e+06</td>\n",
       "      <td>2.697598e+06</td>\n",
       "      <td>lido</td>\n",
       "      <td>lido</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>Lido</td>\n",
       "      <td>Lido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-20 23:00:00</td>\n",
       "      <td>MATIC</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.697598e+06</td>\n",
       "      <td>lido</td>\n",
       "      <td>lido</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>Lido</td>\n",
       "      <td>Lido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-21 23:00:00</td>\n",
       "      <td>WETH</td>\n",
       "      <td>5562.49008</td>\n",
       "      <td>3.410254e+06</td>\n",
       "      <td>3.410254e+06</td>\n",
       "      <td>lido</td>\n",
       "      <td>lido</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Liquid Staking</td>\n",
       "      <td>Lido</td>\n",
       "      <td>Lido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  token token_value     usd_value  total_app_tvl  \\\n",
       "0 2020-12-19 23:00:00   WETH  2272.26688  1.484681e+06   1.484681e+06   \n",
       "1 2020-12-19 23:00:00  MATIC           0  0.000000e+00   1.484681e+06   \n",
       "2 2020-12-20 23:00:00   WETH  4140.77143  2.697598e+06   2.697598e+06   \n",
       "3 2020-12-20 23:00:00  MATIC           0  0.000000e+00   2.697598e+06   \n",
       "4 2020-12-21 23:00:00   WETH  5562.49008  3.410254e+06   3.410254e+06   \n",
       "\n",
       "  protocol  slug     chain        category  name parent_protocol  \n",
       "0     lido  lido  Ethereum  Liquid Staking  Lido            Lido  \n",
       "1     lido  lido  Ethereum  Liquid Staking  Lido            Lido  \n",
       "2     lido  lido  Ethereum  Liquid Staking  Lido            Lido  \n",
       "3     lido  lido  Ethereum  Liquid Staking  Lido            Lido  \n",
       "4     lido  lido  Ethereum  Liquid Staking  Lido            Lido  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display(df_df)\n",
    "df_df_all = df_df.copy()\n",
    "df_df_all.head()\n",
    "# Test for errors\n",
    "# df_df_all[(df_df_all['protocol'] == 'app_name') & (df_df_all['date'] == '2023-01-27')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef17372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_df_all)\n",
    "df_df_all2 = df_df_all.copy()\n",
    "# df_df_all2['token_value'] = df_df_all2['token_value'].fillna(0)\n",
    "df_df_all2['token_value'] = df_df_all2['token_value'].astype('float64')\n",
    "df_df_all2['usd_value'] = df_df_all2['usd_value'].astype('float64')\n",
    "# display(df_df_all2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab956a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               datetime64[ns]\n",
      "token                      object\n",
      "token_value               float64\n",
      "usd_value                 float64\n",
      "total_app_tvl             float64\n",
      "protocol                   object\n",
      "slug                       object\n",
      "chain                      object\n",
      "category                   object\n",
      "name                       object\n",
      "parent_protocol            object\n",
      "dtype: object\n",
      "date               datetime64[ns]\n",
      "token                      object\n",
      "token_value               float64\n",
      "usd_value                 float64\n",
      "total_app_tvl             float64\n",
      "protocol                   object\n",
      "slug                       object\n",
      "chain                      object\n",
      "category                   object\n",
      "name                       object\n",
      "parent_protocol            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create an extra day to handle for tokens dropping to 0\n",
    "\n",
    "df_df_all_u = df_df_all2.fillna(0)\n",
    "df_df_shift = df_df_all_u.copy()\n",
    "df_df_shift['date'] = df_df_shift['date'] + timedelta(days=1)\n",
    "df_df_shift['token_value'] = 0.0\n",
    "df_df_shift['usd_value'] = 0.0\n",
    "\n",
    "#merge back in\n",
    "df_df_all = pd.concat([df_df_all_u,df_df_shift])\n",
    "\n",
    "# print(df_df_all.dtypes)\n",
    "\n",
    "df_df_all = df_df_all[df_df_all['date'] <= pd.to_datetime(\"today\") ]\n",
    "\n",
    "df_df_all['token_value'] = df_df_all['token_value'].fillna(0)\n",
    "df_df_all = df_df_all.groupby(['date','token','chain','protocol','name','category','parent_protocol']).sum(['usd_value','token_value'])\n",
    "\n",
    "\n",
    "df_df_all = df_df_all.reset_index()\n",
    "df_df_shift = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c1ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done api\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df_df_all = pd.concat(df_df_all)\n",
    "# print(df_df_all[2])\n",
    "print(\"done api\")\n",
    "# display(df_df_all[df_df_all['protocol'] == 'velodrome'])\n",
    "# display(df_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c381e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/3025244054.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_df['last_token_value'] = df_df.groupby(['token','protocol','chain'])['token_value'].shift(1)\n"
     ]
    }
   ],
   "source": [
    "#filter down a bit so we can do trailing comparisons w/o doing every row\n",
    "df_df = df_df_all[df_df_all['date'].dt.date >= start_date-timedelta(days=1) ]\n",
    "\n",
    "#trailing comparison\n",
    "df_df['last_token_value'] = df_df.groupby(['token','protocol','chain'])['token_value'].shift(1)\n",
    "#now actually filter\n",
    "df_df = df_df[df_df['date'].dt.date >= start_date ]\n",
    "# display(df_df[df_df['protocol'] == 'velodrome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9eb8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>token</th>\n",
       "      <th>chain</th>\n",
       "      <th>protocol</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>parent_protocol</th>\n",
       "      <th>token_value</th>\n",
       "      <th>usd_value</th>\n",
       "      <th>total_app_tvl</th>\n",
       "      <th>last_token_value</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>last_price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8419763</th>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>USDT</td>\n",
       "      <td>Avalanche</td>\n",
       "      <td>sushi-bentobox</td>\n",
       "      <td>Sushi BentoBox</td>\n",
       "      <td>Yield</td>\n",
       "      <td>Sushi</td>\n",
       "      <td>5.554506e+03</td>\n",
       "      <td>5.582278e+03</td>\n",
       "      <td>8.440953e+05</td>\n",
       "      <td>5.554506e+03</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>0.999808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10891015</th>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>totalLiquidityUSD</td>\n",
       "      <td>Arbitrum</td>\n",
       "      <td>yearn-finance*</td>\n",
       "      <td>Yearn Finance</td>\n",
       "      <td>Yield Aggregator</td>\n",
       "      <td>Yearn Finance</td>\n",
       "      <td>1.603732e+05</td>\n",
       "      <td>1.603732e+05</td>\n",
       "      <td>3.180938e+05</td>\n",
       "      <td>1.577206e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596544</th>\n",
       "      <td>2023-03-04</td>\n",
       "      <td>LUNC</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>terra-bridge</td>\n",
       "      <td>Terra Bridge</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>Terra Bridge</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.375269e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5067333</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>UNKNOWN (harmony:0x59ed4baf5fe05b457cd6de34f58...</td>\n",
       "      <td>Harmony</td>\n",
       "      <td>defi-kingdoms</td>\n",
       "      <td>Defi Kingdoms</td>\n",
       "      <td>Dexes</td>\n",
       "      <td>Defi Kingdoms</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.196421e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281329</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>WMOVR</td>\n",
       "      <td>Moonriver</td>\n",
       "      <td>fantohm</td>\n",
       "      <td>Fantohm</td>\n",
       "      <td>Reserve Currency</td>\n",
       "      <td>Fantohm</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.892339e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219079</th>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>MBABA</td>\n",
       "      <td>Binance</td>\n",
       "      <td>terra-bridge</td>\n",
       "      <td>Terra Bridge</td>\n",
       "      <td>Bridge</td>\n",
       "      <td>Terra Bridge</td>\n",
       "      <td>1.616800e-01</td>\n",
       "      <td>4.489740e+00</td>\n",
       "      <td>3.706856e+07</td>\n",
       "      <td>7.256000e-02</td>\n",
       "      <td>27.769297</td>\n",
       "      <td>53.570700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7452906</th>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>FTX TOKEN</td>\n",
       "      <td>Ethereum-borrowed</td>\n",
       "      <td>euler</td>\n",
       "      <td>Euler</td>\n",
       "      <td>Lending</td>\n",
       "      <td>Euler</td>\n",
       "      <td>1.436337e+05</td>\n",
       "      <td>3.876674e+06</td>\n",
       "      <td>3.964457e+08</td>\n",
       "      <td>1.368718e+05</td>\n",
       "      <td>26.990000</td>\n",
       "      <td>26.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293352</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>USDT</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>dforce</td>\n",
       "      <td>dForce</td>\n",
       "      <td>Lending</td>\n",
       "      <td>dForce</td>\n",
       "      <td>6.047636e+06</td>\n",
       "      <td>6.053684e+06</td>\n",
       "      <td>1.266202e+07</td>\n",
       "      <td>6.183404e+06</td>\n",
       "      <td>1.001000</td>\n",
       "      <td>1.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981829</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>AXL</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>uniswap-v3</td>\n",
       "      <td>Uniswap V3</td>\n",
       "      <td>Dexes</td>\n",
       "      <td>Uniswap</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.392150e+09</td>\n",
       "      <td>1.647768e+05</td>\n",
       "      <td>0.762054</td>\n",
       "      <td>0.762054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029494</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>LOOKS</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>euler</td>\n",
       "      <td>Euler</td>\n",
       "      <td>Lending</td>\n",
       "      <td>Euler</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.527738e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date                                              token  \\\n",
       "8419763  2022-10-20                                               USDT   \n",
       "10891015 2023-02-02                                  totalLiquidityUSD   \n",
       "11596544 2023-03-04                                               LUNC   \n",
       "5067333  2022-05-08  UNKNOWN (harmony:0x59ed4baf5fe05b457cd6de34f58...   \n",
       "5281329  2022-05-20                                              WMOVR   \n",
       "5219079  2022-05-17                                              MBABA   \n",
       "7452906  2022-09-06                                          FTX TOKEN   \n",
       "7293352  2022-08-29                                               USDT   \n",
       "7981829  2022-10-01                                                AXL   \n",
       "7029494  2022-08-17                                              LOOKS   \n",
       "\n",
       "                      chain        protocol            name          category  \\\n",
       "8419763           Avalanche  sushi-bentobox  Sushi BentoBox             Yield   \n",
       "10891015           Arbitrum  yearn-finance*   Yearn Finance  Yield Aggregator   \n",
       "11596544           Ethereum    terra-bridge    Terra Bridge            Bridge   \n",
       "5067333             Harmony   defi-kingdoms   Defi Kingdoms             Dexes   \n",
       "5281329           Moonriver         fantohm         Fantohm  Reserve Currency   \n",
       "5219079             Binance    terra-bridge    Terra Bridge            Bridge   \n",
       "7452906   Ethereum-borrowed           euler           Euler           Lending   \n",
       "7293352            Ethereum          dforce          dForce           Lending   \n",
       "7981829            Ethereum      uniswap-v3      Uniswap V3             Dexes   \n",
       "7029494            Ethereum           euler           Euler           Lending   \n",
       "\n",
       "         parent_protocol   token_value     usd_value  total_app_tvl  \\\n",
       "8419763            Sushi  5.554506e+03  5.582278e+03   8.440953e+05   \n",
       "10891015   Yearn Finance  1.603732e+05  1.603732e+05   3.180938e+05   \n",
       "11596544    Terra Bridge  0.000000e+00  0.000000e+00   1.375269e+08   \n",
       "5067333    Defi Kingdoms  0.000000e+00  0.000000e+00   2.196421e+08   \n",
       "5281329          Fantohm  0.000000e+00  0.000000e+00   1.892339e+06   \n",
       "5219079     Terra Bridge  1.616800e-01  4.489740e+00   3.706856e+07   \n",
       "7452906            Euler  1.436337e+05  3.876674e+06   3.964457e+08   \n",
       "7293352           dForce  6.047636e+06  6.053684e+06   1.266202e+07   \n",
       "7981829          Uniswap  0.000000e+00  0.000000e+00   6.392150e+09   \n",
       "7029494            Euler  0.000000e+00  0.000000e+00   4.527738e+08   \n",
       "\n",
       "          last_token_value  price_usd  last_price_usd  \n",
       "8419763       5.554506e+03   1.005000        0.999808  \n",
       "10891015      1.577206e+05   1.000000        1.000000  \n",
       "11596544      0.000000e+00        NaN             NaN  \n",
       "5067333       0.000000e+00        NaN             NaN  \n",
       "5281329       0.000000e+00        NaN             NaN  \n",
       "5219079       7.256000e-02  27.769297       53.570700  \n",
       "7452906       1.368718e+05  26.990000       26.310000  \n",
       "7293352       6.183404e+06   1.001000        1.001000  \n",
       "7981829       1.647768e+05   0.762054        0.762054  \n",
       "7029494       0.000000e+00        NaN             NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = df_df.copy()\n",
    "data_df = data_df.sort_values(by='date')\n",
    "\n",
    "# price = usd value / num tokens\n",
    "data_df['price_usd'] = data_df['usd_value']/data_df['token_value']\n",
    "data_df['last_price_usd'] = data_df.groupby(['token','protocol', 'chain'])['price_usd'].shift(1)\n",
    "\n",
    "# If first instnace of token, make sure there's no price diff\n",
    "data_df['last_price_usd'] = data_df[['last_price_usd', 'price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "#Forward fill if token drops off\n",
    "data_df['price_usd'] = data_df[['price_usd','last_price_usd']].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "data_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79aa9678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/2266052418.py:16: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  latest_prices_df_raw_prot = data_df[~data_df['price_usd'].isna()][['token','chain','protocol','price_usd']][data_df['token_rank_desc_prot'] ==1]\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/2266052418.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  latest_prices_df_raw = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd']][data_df['token_rank_desc'] ==1]\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/2266052418.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  latest_prices_df_raw_prot_gt0 = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd','protocol']][data_df['token_rank_desc_prot_gt0'] ==1]\n"
     ]
    }
   ],
   "source": [
    "# Find what is the latest token price. This sometimes gets skewed if tokens disappear or supply locked goes to 0\n",
    "# Token's recency rank by chain - For calculating prices\n",
    "data_df['token_rank_desc'] = data_df.groupby(['chain','token'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "# Token's recency rank by chain & app - For calculating prices\n",
    "data_df['token_rank_desc_prot'] = data_df.groupby(['chain','token','protocol'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "# Token's recency rank by chain & app if > 0 - For calculating prices\n",
    "data_df['token_rank_desc_prot_gt0'] = data_df.query('token_value > 0')\\\n",
    "                                    .groupby(['chain', 'token', 'protocol'])['date']\\\n",
    "                                    .rank(method='first', ascending=False)\n",
    "\n",
    "# get latest price either by protocol or in aggregate\n",
    "# if we don't have a match by protocol, then select in aggregate.\n",
    "# This section is messy\n",
    "latest_prices_df_raw_prot = data_df[~data_df['price_usd'].isna()][['token','chain','protocol','price_usd']][data_df['token_rank_desc_prot'] ==1]\n",
    "latest_prices_df_raw = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd']][data_df['token_rank_desc'] ==1]\n",
    "latest_prices_df_raw_prot_gt0 = data_df[~data_df['price_usd'].isna()][['token','chain','price_usd','protocol']][data_df['token_rank_desc_prot_gt0'] ==1]\n",
    "\n",
    "latest_prices_df_prot = latest_prices_df_raw_prot.groupby(['token','chain','protocol']).median('price_usd')\n",
    "latest_prices_df_prot = latest_prices_df_prot.rename(columns={'price_usd':'latest_price_usd_prot'})\n",
    "\n",
    "latest_prices_df = latest_prices_df_raw.groupby(['token','chain']).median('price_usd')\n",
    "latest_prices_df = latest_prices_df.rename(columns={'price_usd':'latest_price_usd_raw'})\n",
    "\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_raw_prot_gt0.groupby(['token','chain','protocol']).median('price_usd')\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_prot_gt0.rename(columns={'price_usd':'latest_price_usd_prot_gt0'})\n",
    "\n",
    "latest_prices_df_prot = latest_prices_df_prot.reset_index()\n",
    "latest_prices_df = latest_prices_df.reset_index()\n",
    "latest_prices_df_prot_gt0 = latest_prices_df_prot_gt0.reset_index()\n",
    "\n",
    "prices_df = data_df[['chain','protocol','token']].drop_duplicates()\n",
    "prices_df = prices_df.merge(latest_prices_df_prot,on=['token','chain','protocol'], how='left')\n",
    "prices_df = prices_df.merge(latest_prices_df,on=['token','chain'], how='left')\n",
    "prices_df = prices_df.merge(latest_prices_df_prot_gt0,on=['token','chain','protocol'], how='left')\n",
    "#Select the latest price we want in priority order\n",
    "prices_df['latest_price_usd'] = \\\n",
    "        prices_df['latest_price_usd_prot'].where(prices_df['latest_price_usd_prot'] > 0, \\\n",
    "        prices_df['latest_price_usd_raw'].where(prices_df['latest_price_usd_raw'] > 0, \\\n",
    "        prices_df['latest_price_usd_prot_gt0']))\n",
    "\n",
    "#Filter down\n",
    "prices_df = prices_df[['chain','protocol','token','latest_price_usd']]\n",
    "\n",
    "prices_df = prices_df[~prices_df['latest_price_usd'].isna()]\n",
    "\n",
    "#Merge back in to the data dataframe\n",
    "data_df = data_df.merge(prices_df,on=['token','chain','protocol'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cc58adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort in date order\n",
    "data_df.sort_values(by='date',inplace=True)\n",
    "\n",
    "# get net token change\n",
    "data_df['net_token_flow'] = data_df['token_value'] - data_df['last_token_value']\n",
    "# get net token change * current price\n",
    "data_df['net_dollar_flow'] = data_df['net_token_flow'] * data_df['price_usd']\n",
    "# get net token change * latest price\n",
    "data_df['net_dollar_flow_latest_price'] = data_df['net_token_flow'] * data_df['latest_price_usd']\n",
    "\n",
    "#Filter out weird errors and things\n",
    "data_df = data_df[abs(data_df['net_dollar_flow']) < 50_000_000_000] #50 bil error bar for bad prices\n",
    "data_df = data_df[~data_df['net_dollar_flow'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74651c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle for errors where a token price went to zero (i.e. magpie ANKRBNB 2023-01-27)\n",
    "data_df['net_dollar_flow_latest_price'] = np.where(\n",
    "    data_df['net_dollar_flow'] == 0, 0, data_df['net_dollar_flow_latest_price']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59f3f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get net flows by protocol\n",
    "\n",
    "netdf_df = data_df[['date','protocol','chain','name','category','parent_protocol','net_dollar_flow','usd_value','net_dollar_flow_latest_price']]\n",
    "netdf_df = netdf_df.fillna(0)\n",
    "netdf_df = netdf_df.sort_values(by='date',ascending=True)\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain','name','category','parent_protocol']).sum(['net_dollar_flow','usd_value','net_dollar_flow_latest_price']) ##agg by app\n",
    "\n",
    "#usd_value is the TVL on a given day\n",
    "netdf_df = netdf_df.groupby(['date','protocol','chain','usd_value','name','category','parent_protocol']).sum(['net_dollar_flow','net_dollar_flow_latest_price'])\n",
    "\n",
    "netdf_df.reset_index(inplace=True)\n",
    "netdf_df.head()\n",
    "\n",
    "# Drop index column if it exists\n",
    "try:\n",
    "        netdf_df.drop(columns=['index'],inplace=True)\n",
    "except:\n",
    "        pass\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ccf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get latest\n",
    "netdf_df['rank_desc'] = netdf_df.groupby(['protocol', 'chain'])['date'].\\\n",
    "                            rank(method='dense',ascending=False).astype(int)\n",
    "# display(netdf_df[netdf_df['protocol'] == 'lyra'])\n",
    "netdf_df = netdf_df[  #( netdf_df['rank_desc'] == 1 ) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-borrowed')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-staking')) &\\\n",
    "                        (~netdf_df['chain'].str.contains('-pool2')) &\\\n",
    "                            (~netdf_df['chain'].str.contains('-treasury')) &\\\n",
    "                        (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'borrowed') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'staking') ) &\\\n",
    "                            (~( netdf_df['chain'] == 'treasury') ) &\\\n",
    "                        (~( netdf_df['chain'] == 'pool2') ) &\\\n",
    "                        (~( netdf_df['protocol'] == 'polygon-bridge-&-staking') )  &\\\n",
    "                            (~(netdf_df['protocol'].str[-4:] == '-cex') )\n",
    "#                         & (~( netdf_df['chain'] == 'Ethereum') )\n",
    "                        ]\n",
    "# display(netdf_df[netdf_df['protocol']=='makerdao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67bdbe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
      "/var/folders/by/kltjc8yd0yz_7_wrtrzhrm9m0000gn/T/ipykernel_70306/181373503.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  .apply(lambda x: x.rolling(i, min_periods=1).sum())\n"
     ]
    }
   ],
   "source": [
    "summary_df = netdf_df.copy()\n",
    "\n",
    "summary_df = summary_df.sort_values(by='date',ascending=True)\n",
    "\n",
    "# Mark at latest price if chosen\n",
    "if mark_at_latest_price == 1:\n",
    "        summary_df['mark_at_latest_price'] = mark_at_latest_price\n",
    "        summary_df['net_dollar_flow'] = summary_df['net_dollar_flow_latest_price']\n",
    "        titleval_append = ' - At Latest Prices'\n",
    "else:\n",
    "        titleval_append = ''\n",
    "\n",
    "# Cast 'net_dollar_flow' to float64 data type\n",
    "summary_df['net_dollar_flow'] = summary_df['net_dollar_flow'].astype('float64')\n",
    "\n",
    "for i in drange:\n",
    "        if i == 0:\n",
    "                summary_df['cumul_net_dollar_flow'] = summary_df[['protocol','chain','net_dollar_flow']]\\\n",
    "                                    .groupby(['protocol','chain']).cumsum()\n",
    "                summary_df['flow_direction'] = np.where(summary_df['cumul_net_dollar_flow']*1.0 >= 0, 1,-1)\n",
    "                summary_df['abs_cumul_net_dollar_flow'] = abs(summary_df['cumul_net_dollar_flow'])\n",
    "\n",
    "        else:\n",
    "                col_str = 'cumul_net_dollar_flow_' + str(i) + 'd'\n",
    "                tvl_str = 'daily_avg_tvl_' + str(i) + 'd'\n",
    "                \n",
    "                #chatgpt version\n",
    "                summary_df[col_str] = summary_df.groupby(['protocol','chain'])['net_dollar_flow']\\\n",
    "                                        .apply(lambda x: x.rolling(i, min_periods=1).sum())\n",
    "\n",
    "                summary_df[tvl_str] = summary_df[['protocol','chain','usd_value']]\\\n",
    "                                    .groupby(['protocol','chain'])['usd_value'].transform(lambda x: x.rolling(i, min_periods=1).mean() )\n",
    "                \n",
    "                summary_df['flow_direction_' + str(i) + 'd'] = np.where(summary_df[col_str]*1.0 >= 0, 1, -1)\n",
    "                summary_df['abs_cumul_net_dollar_flow_' + str(i) + 'd'] = abs(summary_df[col_str])\n",
    "\n",
    "summary_df['pct_of_tvl'] = 100* summary_df['net_dollar_flow'] / summary_df['usd_value']\n",
    "final_summary_df = summary_df[(summary_df['rank_desc'] == 1) & (summary_df['date'] >= pd.to_datetime(\"today\") -timedelta(days=7))]\n",
    "final_summary_df = final_summary_df[final_summary_df['cumul_net_dollar_flow']< 1e20] #weird error handling\n",
    "\n",
    "\n",
    "os.makedirs('csv_outputs', exist_ok=True)\n",
    "os.makedirs('img_outputs', exist_ok=True)\n",
    "os.makedirs('img_outputs/png', exist_ok=True)\n",
    "os.makedirs('img_outputs/svg', exist_ok=True)\n",
    "os.makedirs('img_outputs/html', exist_ok=True)\n",
    "\n",
    "final_summary_df.to_csv('csv_outputs/latest_tvl_app_trends.csv', mode='w', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11155af4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'img_outputs/svg/net_app_flows.svg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m fig_app\u001b[39m.\u001b[39mupdate_traces(root_color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlightgrey\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m fig_app\u001b[39m.\u001b[39mupdate_layout(margin \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(t\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, l\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, r\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, b\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m))\n\u001b[0;32m---> 56\u001b[0m fig\u001b[39m.\u001b[39;49mwrite_image(\u001b[39m\"\u001b[39;49m\u001b[39mimg_outputs/svg/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m saveval \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.svg\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m#\u001b[39;00m\n\u001b[1;32m     57\u001b[0m fig\u001b[39m.\u001b[39mwrite_image(\u001b[39m\"\u001b[39m\u001b[39mimg_outputs/png/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m saveval \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#\u001b[39;00m\n\u001b[1;32m     58\u001b[0m fig\u001b[39m.\u001b[39mwrite_html(\u001b[39m\"\u001b[39m\u001b[39mimg_outputs/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m saveval \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m\"\u001b[39m, include_plotlyjs\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcdn\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/plotly/basedatatypes.py:3821\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3761\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[39mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[1;32m   3763\u001b[0m \u001b[39mobject\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3817\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3818\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3819\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> 3821\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mwrite_image(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/site-packages/plotly/io/_kaleido.py:297\u001b[0m, in \u001b[0;36mwrite_image\u001b[0;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    288\u001b[0m \u001b[39m            \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39mThe 'file' argument '{file}' is not a string, pathlib.Path object, or file descriptor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    294\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         \u001b[39m# We previously succeeded in interpreting `file` as a pathlib object.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m         \u001b[39m# Now we can use `write_bytes()`.\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m         path\u001b[39m.\u001b[39;49mwrite_bytes(img_data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/pathlib.py:1143\u001b[0m, in \u001b[0;36mPath.write_bytes\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39m# type-check for the buffer interface before truncating the file\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m view \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(data)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m   1144\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mwrite(view)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/new-env/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m, mode, buffering, encoding, errors,\n\u001b[1;32m   1120\u001b[0m                            newline)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img_outputs/svg/net_app_flows.svg'"
     ]
    }
   ],
   "source": [
    "\n",
    "# display(summary_df)\n",
    "for i in drange:\n",
    "        fig = ''\n",
    "        if i == 0:\n",
    "                yval = 'abs_cumul_net_dollar_flow'\n",
    "                hval = 'cumul_net_dollar_flow'\n",
    "                cval = 'flow_direction'\n",
    "                saveval = 'net_app_flows'\n",
    "                saveval_app = 'net_app_flows_by_app'\n",
    "                titleval = \"App Net Flows Change by Chain -> App - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "                titleval_app = \"App Net Flows Change by App -> Chain - Last \" + str(trailing_num_days) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "        else:\n",
    "                yval = 'abs_cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                hval = 'cumul_net_dollar_flow_' + str(i) +'d'\n",
    "                cval = 'flow_direction_' + str(i) +'d'\n",
    "                saveval = 'net_app_flows_' + str(i) +'d'\n",
    "                saveval_app = 'net_app_flows_by_app_' + str(i) +'d'\n",
    "                titleval = \"App Net Flows Change by Chain -> App - Last \" + str(i) + \\\n",
    "                            \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "                titleval_app = \"App Net Flows Change by App -> Chain - Last \" + str(i) + \\\n",
    "                                \" Days - (Apps with > $\" + str(min_tvl/1e6) + \"M TVL Shown)\" + titleval_append\n",
    "        if is_fallback_on_raw_tvl:\n",
    "                subtitle = \"<br><sup>*For apps where DefiLlama didn't have flows by token, we use their total change in TVL (including token price change)</sup>\"\n",
    "        else:\n",
    "                subtitle = \"\"\n",
    "\n",
    "        fig = px.treemap(final_summary_df[final_summary_df[yval] !=0], \\\n",
    "                 path=[px.Constant(\"all\"), 'chain', 'protocol'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                 values=yval, color=cval\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                     , title = titleval + subtitle\n",
    "                \n",
    "                , hover_data = [hval]\n",
    "                )\n",
    "        \n",
    "        fig_app = px.treemap(final_summary_df[final_summary_df[yval] !=0], \\\n",
    "                 path=[px.Constant(\"all\"), 'protocol','chain'], \\\n",
    "#                  path=[px.Constant(\"all\"), 'token', 'chain', 'protocol'], \\\n",
    "                 values=yval, color=cval\n",
    "#                 ,color_discrete_map={'-1':'red', '1':'green'})\n",
    "                ,color_continuous_scale='Spectral'\n",
    "                     , title = titleval_app + subtitle\n",
    "                \n",
    "                , hover_data = [hval]\n",
    "                )\n",
    "        \n",
    "        fig.update_traces(root_color=\"lightgrey\")\n",
    "        fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "        fig_app.update_traces(root_color=\"lightgrey\")\n",
    "        fig_app.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "        fig.write_image(\"img_outputs/svg/\" + saveval + \".svg\") #\n",
    "        fig.write_image(\"img_outputs/png/\" + saveval + \".png\") #\n",
    "        fig.write_html(\"img_outputs/html\" + saveval + \".html\", include_plotlyjs='cdn')\n",
    "\n",
    "        fig_app.write_image(\"img_outputs/svg/\" + saveval_app + \".svg\") #\n",
    "        fig_app.write_image(\"img_outputs/png/\" + saveval_app + \".png\") #\n",
    "        fig_app.write_html(\"img_outputs/html\" + saveval_app + \".html\", include_plotlyjs='cdn')\n",
    "\n",
    "        if i == 30:\n",
    "                fig.show()\n",
    "# fig.data[0].textinfo = 'label+text+value'\n",
    "# fig.update_layout(tickprefix = '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f573693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! jupyter nbconvert --to python total_app_net_flows_async.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d537a1638226190f579d6fbb68604c1b09ebc740a69df557abedb49ad78e592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
